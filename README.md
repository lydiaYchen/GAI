# Generative Artificial Intelligence


This repository contains the materials of the  **Seminar on Generative AI ** - Spring 2024 at BeNeFri.



##  <a name='Importantlinks'></a>Important links

- [Paper Reading List](PaperList.md)
- [Review template](review.md)




##  <a name='Coursedescription'></a>Course description

Generative artificial intelligence is ubiquitous in our daily life, generating synthetic images, text, sound tracks, and videos. Example tasks include image synthesis, image styling, text to image synthesizing, voice to text translation, text translation, and question and answering.

The aim of this seminar course is to let students learn the principles and models of generative AI via paper reading, presentation, and discussion. We provide a broad overview on the design of the state-of-the-art generative models, spanning from generative adversarial networks, diffusion models and generative pre-trained transformers (GPT). We will present an array of methodologies and techniques that can efficiently and effectively train generative models against all operational conditions.

The course materials will be based on a mixture of classic and recently published papers. The first 4 lectures, the basic concept of distributed machine learning will be covered, followed by presentations from my PhD students and the students taking this course.



Check [Paper Reading List](PaperList.md)


##  <a name='Courseteam'></a>Course team
This course will be mainly taught by [Prof. Lydia Y Chen]([https://lydiaychen.github.io/]) . The course team is composed of a number of PhDs  who support the course through guest lectures.


Lydia can be always reached at **lydiaychen@ieee.org**. In order to get prompt response about the course, put the email title starting with [GAI24]

##  <a name='Learningobjectives'></a>Learning objectives
- To understand and analyze the basic deep generative models, i.e., autoencoder, generative adversarial networks, diffusion models, and GPT.
- To understand how to train the deep generative models in a centralized and decentralized way
- To understand how generative models applied on different data types, e.g., images, tables, and time series.
- To analyze the performance and computational tradeoff among different generative models
- To understand the use cases of generative models and apply them 

##  <a name='grading'></a>:dart: Grading policy
**All assessment items (reviews and presentation slides) have to be submitted via ILIAS.**

To pass the course, you need to
1. Submit 3 paper reviews (template and requirement can be found [here](review.md) ) (75\% of the final grade)
2. Present at least 1 paper (30 minutes plus Q/A) (25\% of the final grade)
   
* Review deadlines are published on ILIAS.
* Student presentation schedule will be decided through self-signup. The details will be announced in the course. 
   
##  <a name='Materials'></a>Course materials

All slides will be available on the ILIAS prior to the lecture.

##  <a name='Detailedschedule'></a>Detailed schedule


**Week**|**Topic**
:-----|:-----
Week 1 (Feb 19) | Introduction to generative AI  (Lydia)
Week 2 (Feb 26) | Generative adversarial networks (Lydia)
Week 3 (Mar 4)|  Diffusion models  (Lydia)
Week 4 (Mar 11)| Large language models  (Lydia)
Week 5 (Mar 18)| **Self-study**
Week 6 (Mar 25)| Federated tabular generative models (Aditya) and **paper presentation from students**
Week 7 (Apr 1)|No lesson  (Easter Monday)
Week 8 (Apr 8)| Graph diffusion (Abel) and **paper presentation from students**
Week 9 (Apr 15)| Watermark GPT (Choayi) and **paper presentation from students**
Week 10 (Apr 22)| Tabular GPT (Jeroen)and **paper presentation from students**
Week 11 (Apr 29)|  **Paper presentation from students**
Week 12 (May 6)|  **Paper presentation from students** (Online)
Week 13 (May 13)| Writing Reviews
Week 14 (May 20)|Writing Reviews

